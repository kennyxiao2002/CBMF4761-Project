{
  "cells": [
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-04-29T08:38:33.690440Z",
          "start_time": "2025-04-29T08:38:33.439028Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "8462b638-6ffe-4c44-e40b-b5e1ce79096a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, roc_auc_score, average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"final_activity_dataset.csv\")\n",
        "df = df.dropna()\n",
        "\n",
        "print(df.columns)\n",
        "# Should be: ['TargetGene', 'ID', 'GuideSeq', 'TargetSeqContext', 'log2FC']\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['GeneName', 'GuideID', 'GuideSeq', 'TargetSeqContext', 'log2FC'], dtype='object')\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T08:38:33.736991Z",
          "start_time": "2025-04-29T08:38:33.696434Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a340e74db00c904",
        "outputId": "7b3d03c9-5422-4461-aaf2-55e5cf000943"
      },
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(12)\n",
        "\n",
        "# Get unique genes\n",
        "genes = df['GeneName'].unique()\n",
        "\n",
        "# Select holdout genes\n",
        "n_holdout = 300 # choose how many genes to hold out\n",
        "holdout_genes = np.random.choice(genes, n_holdout, replace=False)\n",
        "print(\"Holdout Genes:\", holdout_genes)\n",
        "\n",
        "# Create splits\n",
        "df_test = df[df['GeneName'].isin(holdout_genes)].reset_index(drop=True)\n",
        "df_train = df[~df['GeneName'].isin(holdout_genes)].reset_index(drop=True)\n",
        "\n",
        "print(\"Train size:\", df_train.shape)\n",
        "print(\"Test size:\", df_test.shape)\n",
        "\n"
      ],
      "id": "a340e74db00c904",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Holdout Genes: ['PLP2' 'ZNF501' 'TIAL1' 'SRPR' 'RBM33' 'ACO2' 'SUPT4H1' 'MLX' 'ZNF699'\n",
            " 'SEZ6L2' 'TDGF1' 'PC' 'TAF5L' 'ZFP30' 'PCID2' 'IKZF4' 'ZNF132' 'PHF21A'\n",
            " 'SMU1' 'DIS3L' 'RPL10' 'CPSF7' 'ASNS' 'SP6' 'SCAF4' 'TDRD15' 'C4orf3'\n",
            " 'AEN' 'SETX' 'NKX2-5' 'SDC1' 'ZIC4' 'ZNF530' 'ZNF391' 'YEATS4' 'PTMA'\n",
            " 'RRN3' 'CTPS2' 'POLA1' 'KLF14' 'SETD2' 'PAN3' 'ZNF639' 'FOXA2' 'ZBTB45'\n",
            " 'CLK3' 'DCLRE1B' 'TDRD9' 'OAS1' 'PPIL2' 'EXOSC2' 'ATL2' 'ING3' 'INSM1'\n",
            " 'CMTR2' 'ZNF562' 'FAM98A' 'CNOT11' 'NGDN' 'TRIM37' 'BLOC1S6' 'RRP8'\n",
            " 'NUDC' 'ZNF845' 'DARS' 'CPSF3' 'TNNT2' 'ZNF414' 'SSSCA1' 'SNRNP200'\n",
            " 'ZCCHC3' 'PRDM15' 'TCF24' 'ID2' 'HOXC11' 'MRPL22' 'RBBP8' 'FAM210A'\n",
            " 'MYF5' 'SRCAP' 'ZNF780B' 'ZNF696' 'PGM3' 'MPHOSPH8' 'TGFBRAP1' 'ZNF676'\n",
            " 'GALP' 'ZNF442' 'PGS1' 'PSME2' 'SART3' 'EIF3A' 'RPP40' 'EPOR' 'SMYD2'\n",
            " 'KLF13' 'GBX2' 'UBE2I' 'SCAF1' 'FAM171B' 'TRMT11' 'MXRA7' 'CREB3L4' 'CRX'\n",
            " 'NKRF' 'LSM5' 'SLC51B' 'SNRPD1' 'USF2' 'BOLL' 'C9orf114' 'ETFA' 'C1D'\n",
            " 'CDC37' 'PDCD11' 'NAA15' 'TEP1' 'PAK1IP1' 'POLR2I' 'ZBTB12' 'TWISTNB'\n",
            " 'C8orf33' 'RANBP1' 'KHDC1' 'EIF4G2' 'BAHD1' 'HDX' 'ZNHIT1' 'TMEM214'\n",
            " 'CCDC93' 'PCYT1A' 'DPF3' 'IRS2' 'CENPJ' 'PRDM8' 'HIST1H1A' 'RBM48'\n",
            " 'ZNF484' 'MRPL35' 'CPSF4' 'HOXA11' 'SNIP1' 'COX6B1' 'SLC4A7' 'PRKDC'\n",
            " 'FOXC1' 'NCBP1' 'NHLH1' 'ZNF513' 'TAMM41' 'CCAR2' 'WDR77' 'BAK1' 'ZMAT4'\n",
            " 'N6AMT1' 'ANAPC1' 'TUFM' 'DEAF1' 'FOXN1' 'RPN2' 'ZNF548' 'PITX2'\n",
            " 'ZNF518B' 'MYBBP1A' 'KLC2' 'SASS6' 'DNAJA3' 'BAG3' 'POLR2K' 'BTBD1'\n",
            " 'KNTC1' 'MTPAP' 'PDRG1' 'HOXD1' 'SIGLEC11' 'HOXB4' 'TMEM199' 'HOXB13'\n",
            " 'BRIX1' 'ZBTB40' 'CDS2' 'PUM2' 'WDR4' 'SPATS2L' 'MAFF' 'NKX2-6' 'ZNF22'\n",
            " 'ATP6AP1' 'CFL1' 'ELOF1' 'DLAT' 'DOLPP1' 'ZWINT' 'OSBP' 'BCCIP' 'SETD1B'\n",
            " 'STOML1' 'UQCRQ' 'C12orf65' 'BOLA3' 'CLASRP' 'SMARCC2' 'C9orf40' 'ZNF362'\n",
            " 'NR4A2' 'CDC23' 'FOXA1' 'HAMP' 'NAA38' 'ZNF483' 'CFL2' 'KDM4B' 'RUNX2'\n",
            " 'UBP1' 'TRNT1' 'RORA' 'PROX1' 'ZNF644' 'GLI4' 'TRIM32' 'PABPC3' 'TRAM1'\n",
            " 'MORC2' 'COPS3' 'ANXA2' 'PISD' 'THOC7' 'POLE2' 'OTUD5' 'ZBED2' 'LMX1B'\n",
            " 'SLC30A9' 'QTRT1' 'SNRPD3' 'BACH2' 'TRMT44' 'T' 'ZFP64' 'RBMS3' 'ZFAT'\n",
            " 'TRAF2' 'PAPOLG' 'RERE' 'SUMO1' 'PDAP1' 'ZBTB8OS' 'MAU2' 'C1QBP' 'RPS15A'\n",
            " 'CTDP1' 'EIF1AX' 'ZRSR2' 'CEP152' 'CIC' 'CNBP' 'USP10' 'TOX2' 'JAZF1'\n",
            " 'ZDHHC6' 'ANKRD10' 'ZNF687' 'EN1' 'ZNF532' 'TEAD1' 'ZNF277' 'AHCY' 'PMF1'\n",
            " 'NUS1' 'CTSZ' 'YBX2' 'TADA2A' 'KLHL15' 'UBE2S' 'FAM193A' 'MSI1'\n",
            " 'SUV420H1' 'SSH1' 'PDCD7' 'ZNF655' 'CT62' 'TCF7' 'SNRPG' 'RPN1' 'RBBP6'\n",
            " 'SERBP1' 'ALYREF' 'AQP7' 'DNMT1' 'PCBP2' 'RPS21' 'PPCS' 'ESRRB' 'ZFC3H1'\n",
            " 'MRPS7' 'ZNF79' 'CBLL1' 'ZNF30' 'MTIF3' 'RRP7A' 'URM1']\n",
            "Train size: (213192, 5)\n",
            "Test size: (25221, 5)\n"
          ]
        }
      ],
      "execution_count": 24
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T08:38:33.768294Z",
          "start_time": "2025-04-29T08:38:33.754036Z"
        },
        "id": "fc8f47a1e87d9de6"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "# 1) your one-hot encoder\n",
        "def one_hot_encode(seq, maxlen=30):\n",
        "    mapping = {'A':[1,0,0,0], 'C':[0,1,0,0], 'G':[0,0,1,0], 'T':[0,0,0,1]}\n",
        "    seq = seq.upper()[:maxlen].ljust(maxlen, 'N')\n",
        "    return np.array([mapping.get(b, [0,0,0,0]) for b in seq], dtype=np.float32)\n",
        "\n",
        "# 2) reverse complement helper\n",
        "_comp = {'A':'T','T':'A','C':'G','G':'C','N':'N'}\n",
        "def rev_comp(s):\n",
        "    return ''.join(_comp.get(b, 'N') for b in reversed(s.upper()))\n",
        "\n",
        "# 3) faster align: first window with â‰¥75% matches to rc-guide\n",
        "def align_center(s1, s2, match_len, maxlen):\n",
        "    rc = rev_comp(s2)\n",
        "    thr = int(np.ceil(match_len * 0.75))\n",
        "    for i in range(len(s1) - match_len + 1):\n",
        "        if sum(a==b for a,b in zip(s1[i:i+match_len], rc)) >= thr:\n",
        "            center = i + match_len//2\n",
        "            break\n",
        "    else:\n",
        "        center = len(s1)//2\n",
        "    # crop around center\n",
        "    start = max(0, center - maxlen//2)\n",
        "    end = start + maxlen\n",
        "    window = s1[start:end].ljust(maxlen, 'N')\n",
        "    # guide window: place guide at same center within maxlen\n",
        "    guide_win = ['N'] * maxlen\n",
        "    offset = center - maxlen//2\n",
        "    for j, ch in enumerate(s2):\n",
        "        pos = j + (match_len//2) + offset - (match_len//2)\n",
        "        if 0 <= pos < maxlen:\n",
        "            guide_win[pos] = ch\n",
        "    return window, ''.join(guide_win)\n",
        "\n",
        "# 4) modified Dataset\n",
        "class GuideRNADataset(Dataset):\n",
        "    def __init__(self, df, match_len=5, maxlen=30):\n",
        "        self.match_len = match_len\n",
        "        self.maxlen    = maxlen\n",
        "        self.contexts  = df['TargetSeqContext'].astype(str).tolist()\n",
        "        self.guides    = df['GuideSeq'].astype(str).tolist()\n",
        "        self.labels    = df['log2FC'].astype(np.float32).values\n",
        "        # precompute aligned one-hots\n",
        "        self.X = []\n",
        "        for s1, s2 in zip(self.contexts, self.guides):\n",
        "            a1, a2 = align_center(s1, s2, match_len, maxlen)\n",
        "            x1 = one_hot_encode(a1, maxlen)\n",
        "            x2 = one_hot_encode(a2, maxlen)\n",
        "            self.X.append(np.concatenate([x1, x2], axis=1))  # (maxlen,8)\n",
        "        self.X = np.stack(self.X)  # (N, maxlen,8)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.tensor(self.labels[idx])\n",
        "\n",
        "\n"
      ],
      "id": "fc8f47a1e87d9de6",
      "outputs": [],
      "execution_count": 25
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T08:38:36.140708Z",
          "start_time": "2025-04-29T08:38:33.784644Z"
        },
        "id": "169e5e70d06b9ab1"
      },
      "cell_type": "code",
      "source": [
        "# Flattened input for RF\n",
        "X_train_rf = np.stack(df_train[\"TargetSeqContext\"].apply(one_hot_encode)).reshape(len(df_train), -1)\n",
        "X_test_rf = np.stack(df_test[\"TargetSeqContext\"].apply(one_hot_encode)).reshape(len(df_test), -1)\n",
        "\n",
        "y_train = df_train[\"log2FC\"].values\n",
        "y_test = df_test[\"log2FC\"].values\n"
      ],
      "id": "169e5e70d06b9ab1",
      "outputs": [],
      "execution_count": 26
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T08:43:34.026462Z",
          "start_time": "2025-04-29T08:38:36.157797Z"
        },
        "id": "b2434f74b7d73bda"
      },
      "cell_type": "code",
      "source": [
        "#rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "#rf.fit(X_train_rf, y_train)\n",
        "\n",
        "#y_pred_rf = rf.predict(X_test_rf)\n",
        "\n",
        "#print(\"Random Forest R2 Score:\", r2_score(y_test, y_pred_rf))\n",
        "\n"
      ],
      "id": "b2434f74b7d73bda",
      "outputs": [],
      "execution_count": 27
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T08:43:34.119891Z",
          "start_time": "2025-04-29T08:43:34.099324Z"
        },
        "id": "efbdd151e75f126d"
      },
      "cell_type": "code",
      "source": [
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SmallCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(8, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 30, 256)\n",
        "        self.fc2 = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x.squeeze(1)\n",
        "\n",
        "\n",
        "class LargeCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LargeCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(8, 128, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(512 * 30, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x.squeeze(1)\n",
        "\n",
        "\n"
      ],
      "id": "efbdd151e75f126d",
      "outputs": [],
      "execution_count": 28
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T08:43:36.334689Z",
          "start_time": "2025-04-29T08:43:34.136884Z"
        },
        "id": "957048fee922cf48"
      },
      "cell_type": "code",
      "source": [
        "train_dataset = GuideRNADataset(df_train)\n",
        "test_dataset = GuideRNADataset(df_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "id": "957048fee922cf48",
      "outputs": [],
      "execution_count": 29
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T08:43:36.365003Z",
          "start_time": "2025-04-29T08:43:36.350731Z"
        },
        "id": "c4f4de273b1982c4"
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs=50, patience=5):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                val_losses.append(loss.item())\n",
        "\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={np.mean(train_losses):.4f}, Val Loss={avg_val_loss:.4f}\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    # Load best model state\n",
        "    if best_model_state:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "id": "c4f4de273b1982c4",
      "outputs": [],
      "execution_count": 30
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T09:08:08.933773Z",
          "start_time": "2025-04-29T08:43:36.381823Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b3fb3d4c83c9b1e",
        "outputId": "86a06e79-4fd3-4b48-8c1c-8ffc06e9ce04"
      },
      "cell_type": "code",
      "source": [
        "small_cnn = SmallCNN()\n",
        "trained_small_cnn = train_model(small_cnn, train_loader, test_loader, num_epochs=20)\n",
        "\n",
        "large_cnn = LargeCNN()\n",
        "trained_large_cnn = train_model(large_cnn, train_loader, test_loader, num_epochs=20)\n"
      ],
      "id": "1b3fb3d4c83c9b1e",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=0.9020, Val Loss=0.7182\n",
            "Epoch 2: Train Loss=0.7598, Val Loss=0.7199\n",
            "Epoch 3: Train Loss=0.6358, Val Loss=0.7221\n",
            "Epoch 4: Train Loss=0.5765, Val Loss=0.7306\n",
            "Epoch 5: Train Loss=0.5391, Val Loss=0.7280\n",
            "Epoch 6: Train Loss=0.5137, Val Loss=0.7523\n",
            "Early stopping triggered at epoch 6\n",
            "Epoch 1: Train Loss=0.9024, Val Loss=0.7081\n",
            "Epoch 2: Train Loss=0.7583, Val Loss=0.7086\n",
            "Epoch 3: Train Loss=0.6471, Val Loss=0.7149\n",
            "Epoch 4: Train Loss=0.5864, Val Loss=0.7246\n",
            "Epoch 5: Train Loss=0.5465, Val Loss=0.7231\n",
            "Epoch 6: Train Loss=0.5186, Val Loss=0.7441\n",
            "Early stopping triggered at epoch 6\n"
          ]
        }
      ],
      "execution_count": 31
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-29T09:08:16.429739Z",
          "start_time": "2025-04-29T09:08:16.401741Z"
        },
        "id": "f8736c9ee3270a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67527bb0-38ff-426a-9d07-82fb9c7b39fc"
      },
      "cell_type": "code",
      "source": [
        "def predict_model(model, data_loader):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds.extend(outputs.cpu().numpy())\n",
        "    return np.array(preds)\n",
        "\n",
        "def evaluate_predictions(y_true, y_pred):\n",
        "    pearson_corr, _ = pearsonr(y_true, y_pred)\n",
        "    spearman_corr, _ = spearmanr(y_true, y_pred)\n",
        "\n",
        "    threshold = np.median(y_true)\n",
        "    y_true_binary = (y_true > threshold).astype(int)\n",
        "\n",
        "    auroc = roc_auc_score(y_true_binary, y_pred)\n",
        "    auprc = average_precision_score(y_true_binary, y_pred)\n",
        "\n",
        "    print(f\"Pearson: {pearson_corr:.4f}\")\n",
        "    print(f\"Spearman: {spearman_corr:.4f}\")\n",
        "    print(f\"AUROC: {auroc:.4f}\")\n",
        "    print(f\"AUPRC: {auprc:.4f}\")\n",
        "\n",
        "# Random Forest\n",
        "#evaluate_predictions(y_test, y_pred_rf)\n",
        "\n",
        "# Small CNN\n",
        "y_pred_small = predict_model(trained_small_cnn, test_loader)\n",
        "evaluate_predictions(y_test, y_pred_small)\n",
        "\n",
        "# Large CNN\n",
        "y_pred_large = predict_model(trained_large_cnn, test_loader)\n",
        "evaluate_predictions(y_test, y_pred_large)\n"
      ],
      "id": "f8736c9ee3270a4a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson: 0.3073\n",
            "Spearman: 0.3346\n",
            "AUROC: 0.6574\n",
            "AUPRC: 0.6201\n",
            "Pearson: 0.3244\n",
            "Spearman: 0.3648\n",
            "AUROC: 0.6740\n",
            "AUPRC: 0.6371\n"
          ]
        }
      ],
      "execution_count": 33
    },
    {
      "metadata": {
        "id": "b2ed57b06e8d3310"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 57,
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from captum.attr import IntegratedGradients\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming X_test_tensor exists, create it from test_dataset if needed\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Create a batch of test data\n",
        "X_test_tensor = torch.stack([x for x, y in test_dataset])\n",
        "y_test_tensor = torch.tensor([y for x, y in test_dataset])\n",
        "X_test_tensor = X_test_tensor.to(device)\n",
        "\n",
        "def run_integrated_gradients(model, inputs, n_samples=100):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    ig = IntegratedGradients(model)\n",
        "    baseline = torch.zeros_like(inputs[0]).unsqueeze(0).to(device)\n",
        "    attributions = []\n",
        "\n",
        "    for i in range(min(n_samples, len(inputs))):\n",
        "        attr, _ = ig.attribute(inputs[i].unsqueeze(0), baselines=baseline, return_convergence_delta=True)\n",
        "        attributions.append(attr.squeeze(0).detach().cpu().numpy())\n",
        "    return np.array(attributions)\n",
        "\n",
        "def plot_calibration(y_true, y_pred):\n",
        "    y_true_bin = (y_true > np.median(y_true)).astype(int)\n",
        "    y_pred_norm = (y_pred - np.min(y_pred)) / (np.max(y_pred) - np.min(y_pred))\n",
        "    prob_true, prob_pred = calibration_curve(y_true_bin, y_pred_norm, n_bins=10)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
        "    plt.xlabel(\"Mean Predicted Probability\")\n",
        "    plt.ylabel(\"Fraction of Positives\")\n",
        "    plt.title(\"Calibration Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_predictions(y_true, y_pred):\n",
        "    pearson, _ = pearsonr(y_true, y_pred)\n",
        "    spearman, _ = spearmanr(y_true, y_pred)\n",
        "    y_bin = (y_true > np.median(y_true)).astype(int)\n",
        "    auroc = roc_auc_score(y_bin, y_pred)\n",
        "    auprc = average_precision_score(y_bin, y_pred)\n",
        "    print(f\"Pearson: {pearson:.4f}, Spearman: {spearman:.4f}, AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")\n",
        "    return pearson, spearman, auroc, auprc\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_positive_contributions(attributions):\n",
        "    \"\"\"\n",
        "    attributions: np.ndarray of shape (n_samples, seq_len, 8)\n",
        "    Produces a barplot of positive contributions by (position, base, region).\n",
        "    \"\"\"\n",
        "    ch_labels = [\"T:A\",\"T:C\",\"T:G\",\"T:T\",\"G:A\",\"G:C\",\"G:G\",\"G:T\"]\n",
        "    mean_attr = attributions.mean(axis=0)   # (seq_len, 8)\n",
        "    seq_len, n_ch = mean_attr.shape\n",
        "\n",
        "    records = []\n",
        "    for pos in range(seq_len):\n",
        "        for ch in range(n_ch):\n",
        "            val = mean_attr[pos, ch]\n",
        "            if val > 0:\n",
        "                region, base = ch_labels[ch].split(\":\")\n",
        "                records.append({\n",
        "                    \"Position\": pos + 1,\n",
        "                    \"Region\": \"Target\" if region == \"T\" else \"gRNA\",\n",
        "                    \"Base\": base,\n",
        "                    \"Mean Attribution\": float(val)\n",
        "                })\n",
        "\n",
        "    df_plot = pd.DataFrame.from_records(records)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    sns.heatmap(\n",
        "        data=df_plot,\n",
        "        x=\"Position\", y=\"Mean Attribution\",\n",
        "        hue=\"Base\", palette=\"deep\",\n",
        "        dodge=True\n",
        "    )\n",
        "    plt.axvline(x=28.5, color=\"black\", linestyle=\"--\", label=\"Target/gRNA boundary\")\n",
        "    plt.title(\"Positive Integrated Gradients Contributions by Position and Base\")\n",
        "    plt.xlabel(\"Position in Input Window\")\n",
        "    plt.ylabel(\"Mean Attribution (Positive Only)\")\n",
        "    plt.legend(title=\"Base\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df_plot.sort_values(\"Mean Attribution\", ascending=False)\n"
      ],
      "id": "b2ed57b06e8d3310"
    },
    {
      "cell_type": "code",
      "source": [
        "attributions = run_integrated_gradients(small_cnn, X_test_tensor)\n",
        "plot_positive_contributions(attributions)\n",
        "plot_calibration(y_test, y_pred_small)\n",
        "evaluate_predictions(y_test, y_pred_small)\n",
        "\n",
        "attributions = run_integrated_gradients(large_cnn, X_test_tensor)\n",
        "plot_positive_contributions(attributions)\n",
        "plot_calibration(y_test, y_pred_large)\n",
        "evaluate_predictions(y_test, y_pred_large)"
      ],
      "metadata": {
        "id": "fhnmyZM7Kp_E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "a106cdf0-d5cf-4872-f215-56e946dd2038"
      },
      "id": "fhnmyZM7Kp_E",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Target'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-736b2e3cbad9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mattributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_integrated_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_positive_contributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_calibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-2776f1a6a71a>\u001b[0m in \u001b[0;36mplot_positive_contributions\u001b[0;34m(attributions)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     sns.heatmap(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_plot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Position\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Mean Attribution\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \"\"\"\n\u001b[1;32m    445\u001b[0m     \u001b[0;31m# Initialize the plotter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0m\u001b[1;32m    447\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                           yticklabels, mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Determine good default values for the colormapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[0m\u001b[1;32m    164\u001b[0m                                     cmap, center, robust)\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[0;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# plot_data is a np.ma.array instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mcalc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrobust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Target'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8 (py38)",
      "language": "python",
      "name": "py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}